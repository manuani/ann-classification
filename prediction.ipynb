{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "## import libraries needed to load the model and other functions\n",
    "\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.models import load_model\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import pickle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "## First load the trainedmodel\n",
    "\n",
    "model = load_model(\"/Users/muralis/AIML/data/muralitest.keras\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Read the encoders and scalers stored in the file\n",
    "\n",
    "with open(\"/Users/muralis/AIML/data/genderencoder.pk1\",'rb') as file:\n",
    "    labelencoder_gen = pickle.load(file)\n",
    "file.close()\n",
    "\n",
    "with open(\"/Users/muralis/AIML/data/geoencoder.pk1\",'rb') as file:\n",
    "    geo_encoder = pickle.load(file)\n",
    "file.close()\n",
    "\n",
    "with open(\"/Users/muralis/AIML/data/scalerdump.pk1\",'rb') as file:\n",
    "    scaler = pickle.load(file)\n",
    "file.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Define the input data\n",
    "\n",
    "# Example input data\n",
    "input_data = {\n",
    "    'CreditScore': 600,\n",
    "    'Geography': 'France',\n",
    "    'Gender': 'Male',\n",
    "    'Age': 30,\n",
    "    'Tenure': 3,\n",
    "    'Balance': 6000,\n",
    "    'NumOfProducts': 2,\n",
    "    'HasCrCard': 1,\n",
    "    'IsActiveMember': 1,\n",
    "    'EstimatedSalary': 50000\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   CreditScore Geography  Gender  ...  HasCrCard  IsActiveMember  EstimatedSalary\n",
      "0          600    France       1  ...          1               1            50000\n",
      "\n",
      "[1 rows x 10 columns]\n"
     ]
    }
   ],
   "source": [
    "## change the gender in the input data\n",
    "\n",
    "##convert the input data into a data frame\n",
    "\n",
    "input_df = pd.DataFrame([input_data], columns= [\"CreditScore\",\"Geography\",\"Gender\",\"Age\",\"Tenure\",\"Balance\",\"NumOfProducts\",\"HasCrCard\",\"IsActiveMember\",\"EstimatedSalary\"])\n",
    "input_df[\"Gender\"] = labelencoder_gen.transform(input_df[\"Gender\"])\n",
    "print(input_df.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   Geography_France  Geography_Germany  Geography_Spain\n",
      "0               1.0                0.0              0.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/muralis/AIML/deepl/lib/python3.12/site-packages/sklearn/utils/validation.py:2739: UserWarning: X does not have valid feature names, but OneHotEncoder was fitted with feature names\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "##encode the Geo for the input data\n",
    "geo_encoded_val = geo_encoder.transform([input_df[\"Geography\"]])\n",
    "type(geo_encoded_val)\n",
    "geo_encoded_df = pd.DataFrame(geo_encoded_val.toarray(),columns=geo_encoder.get_feature_names_out([\"Geography\"]))\n",
    "print(geo_encoded_df)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "## drop the geography column form the df and add the geo_encoded_matrix\n",
    "\n",
    "data_to_predict = pd.concat([input_df.drop([\"Geography\"],axis=1), geo_encoded_df], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[-0.52623557  0.91287093 -0.84683466 -0.7014635  -1.13089089  0.76799334\n",
      "   0.64663354  0.97073117 -0.85513815  1.01896773 -0.57035183 -0.59881865]]\n"
     ]
    }
   ],
   "source": [
    "## Use the scalar function on top of it now to normalize the data\n",
    "\n",
    "data_to_predict_scaled = scaler.transform(data_to_predict)\n",
    "print(data_to_predict_scaled)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step\n",
      "[[0.00221969]]\n",
      "0.0022196874\n"
     ]
    }
   ],
   "source": [
    "##predict the outcome\n",
    "\n",
    "prediction = model.predict(data_to_predict_scaled)\n",
    "print(prediction)\n",
    "print(prediction[0][0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if(prediction[0][0],0.5):\n",
    "    print('The probability of customer leaving us is very low')\n",
    "else:\n",
    "    print(\"The probability of customer leaving is very high\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
